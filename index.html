<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Voice-Enabled GIS Map Interface</title>
    <!-- Leaflet CSS for map rendering -->
    <link rel="stylesheet" href="https://unpkg.com/leaflet/dist/leaflet.css" />
    <style>
        /* Basic styling for the map container and voice command controls */
        
        body,
        html {
            margin: 0;
            padding: 0;
            height: 100%;
            font-family: Arial, sans-serif;
        }
        
        #map {
            height: 80vh;
            width: 100%;
        }
        
        #controls {
            position: absolute;
            top: 10px;
            right: 10px;
            z-index: 1000;
            background: rgba(255, 255, 255, 0.9);
            padding: 10px;
            border-radius: 8px;
            box-shadow: 0 0 5px rgba(0, 0, 0, 0.3);
        }
        
        #micButton {
            background-color: #4285f4;
            color: white;
            border: none;
            padding: 10px;
            border-radius: 50%;
            cursor: pointer;
            font-size: 18px;
        }
        
        #commandOutput {
            margin-top: 10px;
            font-size: 14px;
        }
        
        #evaluationReport {
            padding: 10px;
            background: #f9f9f9;
            border-top: 1px solid #ddd;
            font-size: 14px;
        }
    </style>
</head>

<body>
    <!-- Map container -->
    <div id="map"></div>

    <!-- Voice command controls -->
    <div id="controls">
        <button id="micButton" title="Click and speak a command">ðŸŽ¤</button>
        <div id="commandOutput">Awaiting command...</div>
    </div>

    <!-- Evaluation Report Section (for demo purposes) -->
    <div id="evaluationReport">
        <h3>Evaluation Report</h3>
        <ul>
            <li><strong>Response Speed:</strong> Commands are processed in near-real-time.</li>
            <li><strong>Accuracy:</strong> Prototype leverages the Web Speech API; further model improvements (e.g. using GPU-accelerated TensorFlow.js) can boost offline performance.</li>
            <li><strong>User-Friendliness:</strong> Designed for non-technical users with a simple UI and clear feedback.</li>
        </ul>
    </div>

    <!-- Leaflet JS for mapping -->
    <script src="https://unpkg.com/leaflet/dist/leaflet.js"></script>
    <script>
        // Initialize Leaflet map centered over India (example: Ahmedabad)
        var map = L.map('map').setView([23.0225, 72.5714], 5);
        L.tileLayer('https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', {
            attribution: '&copy; OpenStreetMap contributors'
        }).addTo(map);

        // Define sample geospatial layers (road layer and highway layer)
        var roadLayer = L.geoJSON(null, {
            color: 'blue'
        });
        var highwayLayer = L.geoJSON(null, {
            color: 'red'
        });

        // Dummy GeoJSON features for demonstration
        var dummyRoad = {
            "type": "Feature",
            "geometry": {
                "type": "LineString",
                "coordinates": [
                    [72.5714, 23.0225],
                    [72.5800, 23.0300]
                ]
            }
        };

        var dummyHighway = {
            "type": "Feature",
            "geometry": {
                "type": "LineString",
                "coordinates": [
                    [72.5714, 23.0225],
                    [72.6000, 23.0500]
                ]
            }
        };

        roadLayer.addData(dummyRoad);
        highwayLayer.addData(dummyHighway);

        // Set up voice recognition using the Web Speech API
        var SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        var recognition;
        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.lang = 'en-US';
            recognition.interimResults = false;
            recognition.maxAlternatives = 1;
        } else {
            document.getElementById('commandOutput').innerText = "Speech recognition not supported in this browser.";
        }

        // Process recognized voice commands
        function processCommand(command) {
            command = command.toLowerCase();
            document.getElementById('commandOutput').innerText = "Command recognized: " + command;

            // Handle various commands
            if (command.includes("zoom to")) {
                // Example: "zoom to Ahmedabad"
                if (command.includes("ahmedabad")) {
                    map.setView([23.0225, 72.5714], 12);
                }
            } else if (command.includes("show me the road layer")) {
                if (!map.hasLayer(roadLayer)) {
                    roadLayer.addTo(map);
                }
            } else if (command.includes("hide the road layer")) {
                if (map.hasLayer(roadLayer)) {
                    map.removeLayer(roadLayer);
                }
            } else if (command.includes("show me the highways")) {
                if (!map.hasLayer(highwayLayer)) {
                    highwayLayer.addTo(map);
                }
            } else if (command.includes("hide the highways")) {
                if (map.hasLayer(highwayLayer)) {
                    map.removeLayer(highwayLayer);
                }
            } else if (command.includes("zoom in")) {
                map.zoomIn();
            } else if (command.includes("zoom out")) {
                map.zoomOut();
            } else if (command.includes("add marker")) {
                // For demonstration, add a marker at the current center
                var center = map.getCenter();
                L.marker(center).addTo(map)
                    .bindPopup("Marker at " + center.toString()).openPopup();
            } else {
                document.getElementById('commandOutput').innerText += "\nUnknown command.";
            }
        }

        // Set up the microphone button to start voice recognition
        document.getElementById("micButton").addEventListener("click", async function() {
            document.getElementById("commandOutput").innerText = "Recording...";

            try {
                let response = await fetch("http://localhost:8000/transcribe", {
                    method: "POST"
                });
                let data = await response.json();
                let command = data.text.toLowerCase();

                document.getElementById("commandOutput").innerText = "Command recognized: " + command;
                processCommand(command);
            } catch (error) {
                document.getElementById("commandOutput").innerText = "Error: Could not process voice command.";
                console.error("Voice recognition error:", error);
            }
        });

        // Listen for the speech recognition result
        if (recognition) {
            recognition.addEventListener('result', function(event) {
                var transcript = event.results[0][0].transcript;
                processCommand(transcript);
            });
            recognition.addEventListener('error', function(event) {
                document.getElementById('commandOutput').innerText = "Error: " + event.error;
            });
        }
    </script>
</body>

</html>